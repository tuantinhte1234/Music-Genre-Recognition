import numpy as np
import streamlit as st
import base64
import pytube
import os
import subprocess 
import librosa
import tempfile 
from pydub import AudioSegment
import matplotlib.pyplot as plt
import matplotlib.cm as cm
from matplotlib.colors import Normalize
import tensorflow as tf
from statistics import mode
from tensorflow import keras
from keras import regularizers
from keras.preprocessing.image import load_img, img_to_array
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import (Conv2D, MaxPooling2D, Flatten, Dropout, Dense, Activation)
from streamlit_option_menu import option_menu
import time
from openai import OpenAI  
import openai  

# C·∫•u h√¨nh trang
st.set_page_config(page_title="Music AI Website", layout="wide")

# T√πy ch·ªânh CSS cho Sidebar
st.markdown(
    """
    <style>
        [data-testid="stSidebar"] {
            background-image: url("https://cdn.pixabay.com/photo/2024/02/26/14/13/sky-8598072_1280.jpg");
            background-size: cover;
        }
        .css-1d391kg {
            background-color: rgba(0,0,0,0.8) !important;
        }
        .stButton>button {
            width: 100%;
            border-radius: 10px;
            background: linear-gradient(to right, #ff7e5f, #feb47b);
            color: white;
        }
        .stButton>button:hover {
            transform: scale(1.05);
            transition: 0.3s;
        }
    </style>
    """,
    unsafe_allow_html=True
)

# T·∫°o menu Sidebar c√≥ icon
with st.sidebar:
    st.markdown(
        '<img src="https://media.giphy.com/media/xThtapIXXGuYEnqNgU/giphy.gif" width="100%">',
        unsafe_allow_html=True
    )
    menu = option_menu(
        menu_title="Navigation",
        options=["Home", "Create Lyric", "Feel The Beat", "Classify", "Explore", "Library", "Search"],
        icons=["house", "music-note-list", "soundwave", "graph-up", "globe", "book", "search"],
        menu_icon="menu-button-wide",
        default_index=0,
        styles={
            "container": {"background-color": "rgba(0,0,0,0.8)", "padding": "5px"},
            "icon": {"color": "#feb47b", "font-size": "20px"},
            "nav-link": {"font-size": "18px", "color": "#ffffff", "text-align": "left", "margin": "5px"},
            "nav-link-selected": {"background-color": "#ff7e5f"},
        }
    )
    






# N·∫øu ch·ªçn "Classify", hi·ªÉn th·ªã n·ªôi dung n√†y
if menu == "Classify":
    st.markdown("<h1 style='text-align: center; color: white;'>Music Genre Recognition</h1>", unsafe_allow_html=True)

    # Upload file mp3
    st.write("## Upload an MP3 file to classify:")
    mp3_file = st.file_uploader("Upload an audio file", type=["mp3"], label_visibility="collapsed")    
    
    if mp3_file is not None:
        st.write("**Play the song below:**")
        st.audio(mp3_file, "audio/mp3")

        # H√†m chuy·ªÉn ƒë·ªïi MP3 sang WAV
        def convert_mp3_to_wav(music_file):  
            sound = AudioSegment.from_mp3(music_file)
            sound.export("music_file.wav", format="wav")

        # H√†m t·∫°o Mel Spectrogram
        def create_melspectrogram(wav_file):  
            y, sr = librosa.load(wav_file)  
            mel_spec = librosa.power_to_db(librosa.feature.melspectrogram(y=y, sr=sr))    
            plt.figure(figsize=(10, 5))
            plt.axes([0., 0., 1., 1.], frameon=False, xticks=[], yticks=[])
            librosa.display.specshow(mel_spec, x_axis="time", y_axis='mel', sr=sr)
            plt.margins(0)
            plt.savefig('melspectrogram.png')

        # X√¢y d·ª±ng m√¥ h√¨nh CNN
        def GenreModel(input_shape=(100,200,4), classes=10):
            classifier = Sequential()
            classifier.add(Conv2D(8, (3, 3), input_shape=input_shape, activation='relu'))
            classifier.add(MaxPooling2D(pool_size=(2, 2)))
            classifier.add(Conv2D(16, (3, 3), activation='relu'))
            classifier.add(MaxPooling2D(pool_size=(2, 2)))
            classifier.add(Conv2D(32, (3, 3), activation='relu'))
            classifier.add(MaxPooling2D(pool_size=(2, 2)))
            classifier.add(Conv2D(64, (3, 3), activation='relu'))
            classifier.add(MaxPooling2D(pool_size=(2, 2)))
            classifier.add(Conv2D(128, (3, 3), activation='relu'))
            classifier.add(MaxPooling2D(pool_size=(2, 2)))
            classifier.add(Flatten())
            classifier.add(Dropout(0.5))
            classifier.add(Dense(256, activation='relu', kernel_regularizer=regularizers.l2(0.0001)))
            classifier.add(Dropout(0.25))
            classifier.add(Dense(10, activation='softmax'))
            classifier.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])
            return classifier

        # D·ª± ƒëo√°n th·ªÉ lo·∫°i nh·∫°c
        def predict(image_data, model):   
            image = img_to_array(image_data)   
            image = np.reshape(image, (1, 100, 200, 4))   
            prediction = model.predict(image / 255)   
            prediction = prediction.reshape((10,))     
            class_label = np.argmax(prediction)     
            return class_label, prediction

        # Nh√£n c·ªßa c√°c th·ªÉ lo·∫°i nh·∫°c
        class_labels = ['blues', 'classical', 'country', 'disco', 'hiphop', 'jazz', 'metal', 'pop', 'reggae', 'rock']

        # Load m√¥ h√¨nh
        model = GenreModel(input_shape=(100, 200, 4), classes=10)
        model.load_weights("music_genre_recog_model.h5")

        # Hi·ªáu ·ª©ng loading
        with st.spinner("üîç Analyzing music genre..."):
            time.sleep(2)

        # Chuy·ªÉn ƒë·ªïi file v√† t·∫°o spectrogram
        convert_mp3_to_wav(mp3_file)
        audio_full = AudioSegment.from_wav('music_file.wav')

        class_labels_total = []
        predictions_total = []
        for w in range(int(round(len(audio_full) / 3000, 0))):
            audio_3sec = audio_full[3 * (w) * 1000: 3 * (w + 1) * 1000]
            audio_3sec.export(out_f="audio_3sec.wav", format="wav")
            create_melspectrogram("audio_3sec.wav")
            image_data = load_img('melspectrogram.png', color_mode='rgba', target_size=(100, 200))   
            class_label, prediction = predict(image_data, model)
            class_labels_total.append(class_label)
            predictions_total.append(prediction)

        # L·∫•y th·ªÉ lo·∫°i c√≥ d·ª± ƒëo√°n cao nh·∫•t
        class_label_final = mode(class_labels_total)
        predictions_final = np.mean(predictions_total, axis=0)

        # Hi·ªÉn th·ªã k·∫øt qu·∫£
        st.success(f"‚úÖ The genre of your song is: **{class_labels[class_label_final]}**")
        # Hi·ªÉn th·ªã bi·ªÉu ƒë·ªì x√°c su·∫•t d·ª± ƒëo√°n
        fig, ax = plt.subplots(figsize=(10, 5))
        ax.bar(class_labels, predictions_final, color=cm.viridis(np.linspace(0, 1, len(class_labels))))
        ax.set_xlabel("Music Genre")
        ax.set_ylabel("Prediction Probability")
        ax.set_title("Genre Prediction Probability Distribution")
        ax.set_xticklabels(class_labels, rotation=45)
        # Hi·ªÉn th·ªã bi·ªÉu ƒë·ªì trong Streamlit
        st.pyplot(fig)

